{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMa4ojybVEHN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/MullaAhmed/AWS-Training.git\n",
        "%cd /AWS-Training/yolov5\n",
        "!pip install -r requirements.txt\n",
        "!pip install wandb==0.12.10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W31dggXEooem"
      },
      "source": [
        "Go to AWS-Training/yolov5/data/coco128.yaml\n",
        "and edit the paths\n",
        "\n",
        "Data: https://drive.google.com/drive/folders/1ezvKXpNCGHnZuBNhOTpgt7Vwxs5sUGgN?usp=sharing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'--weights' =  'initial weights path'\n",
        "\n",
        "'--cfg' = 'model.yaml path'\n",
        "\n",
        "'--data' = 'dataset.yaml path'\n",
        "\n",
        "'--hyp' = 'hyperparameters path'\n",
        "\n",
        "'--epochs'\n",
        "\n",
        "'--batch-size' = 'total batch size for all GPUs, -1 for autobatch'\n",
        "\n",
        "'--imgsz', '--img', '--img-size' = 'train, val image size (pixels)'\n",
        "\n",
        "'--rect' = 'rectangular training'\n",
        "\n",
        "'--resume', nargs='?' = 'resume most recent training'\n",
        "\n",
        "'--nosave' = 'only save final checkpoint'\n",
        "\n",
        "'--noval' = 'only validate final epoch'\n",
        "\n",
        "'--noautoanchor' = 'disable AutoAnchor'\n",
        "\n",
        "'--noplots' = 'save no plot files'\n",
        "\n",
        "'--evolve' = 'evolve hyperparameters for x generations'\n",
        "\n",
        "'--bucket' = 'gsutil bucket'\n",
        "\n",
        "'--cache' = '--cache images in \"ram\" (default or \"disk\"'\n",
        "\n",
        "'--image-weights' = 'use weighted image selection for training'\n",
        "\n",
        "'--device' = 'cuda device, i.e. 0 or 0,1,2,3 or cpu'\n",
        "\n",
        "'--multi-scale' = 'vary img-size +/- 50%%'\n",
        "\n",
        "'--single-cls' = 'train multi-class data as single-class'\n",
        "\n",
        "'--optimizer' , choices=['SGD', 'Adam', 'AdamW'], default='SGD', help='optimizer'\n",
        "\n",
        "'--sync-bn' = 'use SyncBatchNorm, only available in DDP mode'\n",
        "\n",
        "'--workers' = 'max dataloader workers (per RANK in DDP mode'\n",
        "\n",
        "'--project' = 'save to project/name'\n",
        "\n",
        "'--name' = 'save to project/name'\n",
        "\n",
        "'--exist-ok' = 'existing project/name ok, do not increment'\n",
        "\n",
        "'--quad' = 'quad dataloader'\n",
        "\n",
        "'--cos-lr' = 'cosine LR scheduler'\n",
        "\n",
        "'--label-smoothing' = 'Label smoothing epsilon'\n",
        "\n",
        "'--patience' = 'EarlyStopping patience (epochs without improvement'\n",
        "\n",
        "'--freeze', nargs='+', = 'Freeze layers: backbone=10, first3=0 1 2'\n",
        "\n",
        "'--save-period' = 'Save checkpoint every x epochs (disabled if < 1'\n",
        "\n",
        "'--local_rank' = 'DDP parameter, do not modify'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0q66Uc6V98_",
        "outputId": "c03fa1bb-1734-4210-c042-04b0cd48ec22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l6.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
            "YOLOv5 ðŸš€ 2022-5-4 torch 1.11.0+cu113 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   3540480  models.common.Conv                      [512, 768, 3, 2]              \n",
            "  8                -1  3   5611008  models.common.C3                        [768, 768, 3]                 \n",
            "  9                -1  1   7079936  models.common.Conv                      [768, 1024, 3, 2]             \n",
            " 10                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            " 11                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 12                -1  1    787968  models.common.Conv                      [1024, 768, 1, 1]             \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  3   6200832  models.common.C3                        [1536, 768, 3, False]         \n",
            " 16                -1  1    394240  models.common.Conv                      [768, 512, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 20                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 24                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 27                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
            " 29                -1  3   5807616  models.common.C3                        [1024, 768, 3, False]         \n",
            " 30                -1  1   5309952  models.common.Conv                      [768, 768, 3, 2]              \n",
            " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 32                -1  3  10496000  models.common.C3                        [1536, 1024, 3, False]        \n",
            " 33  [23, 26, 29, 32]  1     69228  models.yolo.Detect                      [4, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [256, 512, 768, 1024]]\n",
            "Model summary: 607 layers, 76185580 parameters, 76185580 gradients, 110.2 GFLOPs\n",
            "\n",
            "Transferred 787/795 items from yolov5l6.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 131 weight (no decay), 135 weight, 135 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/CV/Cancer Wiki Dataset/train/labels.cache' images and labels... 2000 found, 0 missing, 0 empty, 0 corrupt: 100% 2000/2000 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/CV/Cancer Wiki Dataset/val/labels.cache' images and labels... 1000 found, 0 missing, 0 empty, 0 corrupt: 100% 1000/1000 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/train/exp5/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m6.06 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp5\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "  0% 0/125 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "! python train.py --img 640 --batch 16 --epochs 10 --data coco128.yaml --weights yolov5l6.pt \n",
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "# ! python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5l6.pt --resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVpXln7EYyca"
      },
      "outputs": [],
      "source": [
        "! python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5l6.pt --resume"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
